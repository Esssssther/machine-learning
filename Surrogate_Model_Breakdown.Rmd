---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
options(scipen = 999)
library(tidyverse)
library(tidymodels)
library(solitude) # -- new package 
library(janitor)
library(ggpubr)
library(skimr)
library(lubridate)
library(reshape2)
library(vip)
library(NeuralNetTools)
library(DALEX)    # new 
library(DALEXtra) # new 
```

```{r}
labels<-read_csv("smilegate_1M_labels.csv",na=c("null","nan","","NA","n/a")) %>% clean_names()
skim(labels)

```
```{r}
transaction<-read_csv("smilegate_1M_transactions.csv",na=c("null","nan","","NA","n/a")) %>% clean_names()
skim(transaction)
head(transaction)
```
```{r}
set.seed(12)

dtsplit<- initial_split(transaction,prop = 0.7)
isotrain<- training(dtsplit)
isotest<- testing(dtsplit)
isotrain1<-isotrain %>% dplyr::select_if(is.numeric)
isotest1<- isotest %>% dplyr::select_if(is.numeric)
so_recipe <- recipe( ~ 	registration_deposit+mean_deposit+mean_txn+monetary_returns_5day+
                       monetary_returns_15day+monetary_returns_30day+game_cash_count_3day+distinct_account_3day, isotrain1) %>% 
  step_impute_median(all_numeric_predictors()) %>%
#  step_normalize(all_numeric_predictors())  %>%
  prep()


bake_iso<-bake(so_recipe,isotrain1)

```


```{r}
iso_forest <- isolationForest$new(
  sample_size = 2048,
  num_trees = 100,
  max_depth = 12)


iso_forest$fit(bake_iso)
```

```{r}
pred_train <- iso_forest$predict(bake_iso)

pred_train %>%
  ggplot(aes(average_depth)) +
  geom_histogram(bins=20) + 
  geom_vline(xintercept = 9.9, linetype="dotted", 
                color = "blue", size=1.5) + 
  labs(title="Isolation Forest Average Tree Depth")

pred_train %>%
  ggplot(aes(anomaly_score)) +
  geom_histogram(bins=20) + 
  geom_vline(xintercept = 0.62, linetype="dotted", 
                color = "blue", size=1.5) + 
  labs(title="Isolation Forest Anomaly Score Above 0.62")
```
```{r}
bake_test<-bake(so_recipe,isotest1)
pred_test <- iso_forest$predict(bake_test)

pred_test %>%
  ggplot(aes(average_depth)) +
  geom_histogram(bins=20) + 
  geom_vline(xintercept = 9.9, linetype="dotted", 
                color = "blue", size=1.5) + 
  labs(title="Isolation Forest Average Tree Depth")

pred_test %>%
  ggplot(aes(anomaly_score)) +
  geom_histogram(bins=20) + 
  geom_vline(xintercept = 0.62, linetype="dotted", 
                color = "blue", size=1.5) + 
  labs(title="Isolation Forest Anomaly Score Above 0.62")
```


```{r}
train_pred <- bind_cols(pred_train,bake_iso) %>%
  mutate(anomaly = as.factor(if_else(average_depth <=9.9, "Anomaly","Normal")))

train_pred %>%
  arrange(average_depth) %>%
  count(anomaly)
train_pred_score <- bind_cols(pred_train,bake_iso) %>%
  mutate(anomaly = as.factor(if_else(anomaly_score >=0.62, "Anomaly","Normal")))

train_pred_score %>%
  arrange(anomaly_score) %>%
  count(anomaly)
```


```{r}
synth_train <- bind_cols(pred_train, isotrain) %>%
  mutate(synthetic_target = as.factor(
      if_else(average_depth <= 9.9,"fraud","legit")),
         synthetic_target2 = as.factor(
           if_else(anomaly_score >= 0.62,"fraud","legit"))
         )
synth_train%>%
count(synthetic_target,synthetic_target2)

```
```{r}
synth_test <- bind_cols(pred_test, isotest) %>%
  mutate(synthetic_target = as.factor(
      if_else(average_depth <= 9.9,"fraud","legit")),
         synthetic_target2 = as.factor(
           if_else(anomaly_score >= 0.62,"fraud","legit"))
         )
synth_test%>%
count(synthetic_target,synthetic_target2)
```


```{r}
train_w_label<-synth_train %>%
  inner_join(labels,by="transaction_id")%>%
  mutate(event_label=factor(event_label))

test_w_label<-synth_test %>%
  inner_join(labels,by="transaction_id")%>%
  mutate(event_label=factor(event_label))


```


```{r}
# precision,recall
train_w_label %>%
  yardstick::precision(event_label, synthetic_target)%>%
mutate(part="train")%>%
  bind_rows(train_w_label %>%
    yardstick::recall(event_label, synthetic_target)%>%
    mutate(part="train"))%>%
  bind_rows(test_w_label %>%
  yardstick::precision(event_label, synthetic_target)%>%
    mutate(part="test")%>%
  bind_rows(test_w_label %>%
  yardstick::recall(event_label, synthetic_target)%>%mutate(part="test")))
```
```{r}
# precision,recall
train_w_label %>%
  yardstick::precision(event_label, synthetic_target2)%>%
mutate(part="train")%>%
  bind_rows(train_w_label %>%
    yardstick::recall(event_label, synthetic_target2)%>%
    mutate(part="train"))%>%
  bind_rows(test_w_label %>%
  yardstick::precision(event_label, synthetic_target2)%>%
    mutate(part="test")%>%
  bind_rows(test_w_label %>%
  yardstick::recall(event_label, synthetic_target2)%>%mutate(part="test")))
```
```{r}
train_w_label$synthetic_target2<-as.factor(train_w_label$synthetic_target2)
model_recipe <- recipe(synthetic_target2 ~ 	registration_deposit+mean_deposit+mean_txn+monetary_returns_5day+
                       monetary_returns_15day+monetary_returns_30day+game_cash_count_3day+distinct_account_3day,data = train_w_label) %>% 
prep()


bake_train<-bake(model_recipe, train_w_label)
skim(bake_train)
```


```{r}
rf_model <- rand_forest(trees = 100, mtry=13,min_n = 10) %>%
   set_mode("classification") %>%
   set_engine("ranger", importance="permutation")
#num.threads = 8 , max.depth = 10
rf_workflow <- workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(rf_model) %>%
    fit(train_w_label)

rf_workflow
```

```{r}
options(yardstick.event_first = TRUE)
# score training
predict(rf_workflow, train_w_label, type = "prob") %>%
  bind_cols(predict(rf_workflow, train_w_label, type = "class")) %>%
  mutate(part = "train_w_label") %>%
  bind_cols(., train_w_label) -> scored_train

predict(rf_workflow, test_w_label, type = "prob") %>%
  bind_cols(predict(rf_workflow,  test_w_label, type = "class")) %>%
  mutate(part = "test_w_label") %>%
  bind_cols(., test_w_label) -> scored_test
```
```{r}
# precision,recall
scored_train %>%
  yardstick::precision(event_label, .pred_class)%>%
mutate(part="train")%>%
    bind_rows(scored_test %>%
  yardstick::precision(event_label, .pred_class)%>%
    mutate(part="test")%>%
  bind_rows(scored_train %>%
    yardstick::recall(event_label, .pred_class)%>%
    mutate(part="train"))%>%
  bind_rows(scored_test %>%
  yardstick::recall(event_label, .pred_class)%>%mutate(part="test")))
```
```{r}
## Metrics (AUC / Accuracy / Log Loss)
bind_rows (scored_train, scored_test)  %>%
  group_by(part) %>%
  metrics(event_label, .pred_fraud, estimate = .pred_class) %>%
  filter(.metric %in% c('accuracy', 'roc_auc', 'mn_log_loss')) %>%
  pivot_wider(names_from = .metric, values_from = .estimate)
```
```{r}
model_recipe_original <- recipe(event_label ~ 	registration_deposit+mean_deposit+mean_txn+monetary_returns_5day+
                       monetary_returns_15day+monetary_returns_30day+game_cash_count_3day+distinct_account_3day,data = train_w_label) %>% 
prep()


bake_train<-bake(model_recipe_original, train_w_label)
skim(bake_train)
```

```{r}

#num.threads = 8 , max.depth = 10
rf_workflow_original <- workflow() %>%
  add_recipe(model_recipe_original) %>%
  add_model(rf_model) %>%
    fit(train_w_label)

rf_workflow_original
```


```{r}
options(yardstick.event_first = TRUE)
# score training
predict(rf_workflow_original, train_w_label, type = "prob") %>%
  bind_cols(predict(rf_workflow_original, train_w_label, type = "class")) %>%
  mutate(part = "train") %>%
  bind_cols(., train_w_label) -> scored_train_original

predict(rf_workflow_original, test_w_label, type = "prob") %>%
  bind_cols(predict(rf_workflow_original,  test_w_label, type = "class")) %>%
  mutate(part = "test") %>%
  bind_cols(., test_w_label) -> scored_test_original
```


```{r}
# precision,recall
scored_train_original %>%
  yardstick::precision(event_label, .pred_class)%>%
mutate(part="train")%>%
  bind_rows(scored_test_original %>%
  yardstick::precision(event_label, .pred_class)%>%
    mutate(part="test")%>%
  bind_rows(scored_train_original %>%
    yardstick::recall(event_label, .pred_class)%>%
    mutate(part="train"))%>%
  bind_rows(scored_test_original %>%
  yardstick::recall(event_label, .pred_class)%>%mutate(part="test")))
```

```{r}
## Metrics (AUC / Accuracy / Log Loss)
bind_rows (scored_train_original, scored_test_original)  %>%
  group_by(part) %>%
  metrics(event_label, .pred_fraud, estimate = .pred_class) %>%
  filter(.metric %in% c('accuracy', 'roc_auc', 'mn_log_loss')) %>%
  pivot_wider(names_from = .metric, values_from = .estimate)
```


```{r}
train_w_label_sample <- train_w_label %>% sample_n(1000)




rf_explainer_surrogate <- 
  explain_tidymodels(
    rf_workflow,   # fitted workflow object 
    data = train_w_label_sample,    # original training data
    y = train_w_label_sample$event_label, # predicted outcome 
    label = "rf_explainer_surrogate",
    verbose = FALSE
  )




explain_prediction <- function(single_record){
 
# step 3. run the explainer 
rf_breakdown_surrogate <- predict_parts(explainer = rf_explainer_surrogate, 
                               new_observation = single_record,
                               type="break_down"
                               )

# step 4. plot it. 
# you notice you don't get categorical values ...  
rf_breakdown_surrogate %>% plot()%>%print()

# --- more involved explanations with categories. ---- 

# step 4a.. convert breakdown to a tibble so we can join it
rf_breakdown_surrogate %>%
  as_tibble() -> breakdown_data_surrogate 

# step 4b. transpose your single record prediction 
single_record %>% 
 gather(key="variable_name",value="value") -> prediction_data_surrogate 

# step 4c. get a predicted probability for plot 
prediction_prob_surrogate <- single_record[,".pred_fraud"] %>% pull()

# step 5. plot it.
print(breakdown_data_surrogate %>% 
  inner_join(prediction_data_surrogate) %>%
  mutate(contribution = round(contribution,3),) %>%
  filter(variable_name != "intercept") %>%
  mutate(variable = paste(variable_name,value,sep = ": ")) %>% 
  ggplot(aes(y=reorder(variable, contribution), x= contribution, fill=sign)) +
  geom_col() + 
  geom_text(aes(label=contribution), 
          size=4,
            position=position_dodge(width=0.7),
            vjust=0.5,
            )+
  labs(
    title = "DALEX explainations",
    subtitle = paste("predicted:",as.character(round(prediction_prob_surrogate,3))),
                    x="contribution",
                    y="features")
)
}

top_10_surrogate <- scored_test %>%
  filter(.pred_class == event_label) %>%
  filter(event_label == "fraud")%>%
  slice_max(.pred_fraud,n=10)%>%
  head(10)


for (row in 1:nrow(top_10_surrogate)) {
    s_record_surrogate <- top_10_surrogate[row,]
    explain_prediction(s_record_surrogate)
} 




```






```{r}



rf_explainer_original <- 
  explain_tidymodels(
    rf_workflow_original,   # fitted workflow object 
    data = train_w_label_sample,    # original training data
    y = train_w_label_sample$event_label, # predicted outcome 
    label = "rf_explainer_original",
    verbose = FALSE
  )

explain_prediction2 <- function(single_record){
# step 3. run the explainer 
rf_breakdown_original <- predict_parts(explainer = rf_explainer_original, 
                               new_observation = single_record,
                               type="break_down"
                               )

# step 4. plot it. 
# you notice you don't get categorical values ...  
rf_breakdown_original %>% plot()%>%print()

# --- more involved explanations with categories. ---- 

# step 4a.. convert breakdown to a tibble so we can join it
rf_breakdown_original %>%
  as_tibble() -> breakdown_data_origianl 

# step 4b. transpose your single record prediction 
single_record %>% 
 gather(key="variable_name",value="value") -> prediction_data_original

# step 4c. get a predicted probability for plot 
prediction_prob_original <- single_record[,".pred_fraud"] %>% pull()

# step 5. plot it.
print(breakdown_data_origianl %>% 
  inner_join(prediction_data_original) %>%
  mutate(contribution = round(contribution,3),) %>%
  filter(variable_name != "intercept") %>%
  mutate(variable = paste(variable_name,value,sep = ": ")) %>% 
  ggplot(aes(y=reorder(variable, contribution), x= contribution, fill=sign)) +
  geom_col() + 
  geom_text(aes(label=contribution), 
          size=4,
            position=position_dodge(width=0.7),
            vjust=0.5,
            )+
  labs(
    title = "DALEX explainations",
    subtitle = paste("predicted:",as.character(round(prediction_prob_original,3))),
                    x="contribution",
                    y="features")
)
  }

top_10_original <- scored_test_original %>%
  filter(.pred_class == event_label) %>%
  filter(event_label=="fraud")%>%
  slice_max(.pred_fraud,n=10)%>%
  head(10)


for (row in 1:nrow(top_10_original)) {
    s_record_original <- top_10_original[row,]
  explain_prediction2(s_record_original)
} 
```



Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

